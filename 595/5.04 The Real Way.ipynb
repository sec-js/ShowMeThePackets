{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b887ab2-61c8-4334-8f53-0059629b51f5",
   "metadata": {},
   "source": [
    "# Anomaly Detection in Logs\n",
    "\n",
    "The lab provides a practical demonstration of how an autoencoder can be used to identify anomalies. While this works, I chose to encode character by character in order to provide an intuitive understanding of what a high loss value looks like. In this notebook, we approach the problem \"a real way.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe68e31-0cbb-462d-992b-05b3ed7ec3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767122695.665414   84700 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1767122695.698019   84700 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767122696.502095   84700 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a103c1d-2a8c-4df2-8bbe-deddbecc48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This max_length is 20% longer than the longest tokenized entry in the training data.\n",
    "max_length = 32\n",
    "\n",
    "\n",
    "# We do still need to load the logs for training.\n",
    "with open('../data/Day 5/messages', 'r') as f:\n",
    "    log_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92aa8fe9-9a15-4077-ae0e-25a570d538a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's use a tokenizer to tokenize the \"words\"\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "tokenizer.train(['../data/Day 5/messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026d8661-b90c-4c21-9a77-5eeb2c97ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['munnin rsyslogd: [origin software=\"rsyslogd\" swVersion=\"8.24.0-57.amzn2.2.0.1\" x-pid=\"3223\" x-info=\"http://www.rsyslog.com\"] rsyslogd was HUPed',\n",
       " 'munnin systemd: Removed slice User Slice of root.',\n",
       " 'munnin dhclient[3034]: XMT: Solicit on eth0, interval 108620ms.',\n",
       " 'munnin systemd: Created slice User Slice of root.',\n",
       " 'munnin systemd: Started Session 263 of user root.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It still makes sense to strip the timestamps to avoid inflating loss.\n",
    "log_data = [line[16:-1] for line in log_data]\n",
    "log_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1920bb3-7191-40d5-91d5-4787b90d7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we will not remove the numbers this time. \n",
    "# Let's encode all of the lines:\n",
    "\n",
    "\n",
    "def preprocess_data(x):\n",
    "    data = [tokenizer.encode(i).ids for i in x]\n",
    "    return np.array([((i * round((max_length / (len(i))+1)))[:max_length]) for i in data])\n",
    "    \n",
    "x = preprocess_data(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed58ffe-ec2a-442c-b1a2-8226e2a38cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1767122700.069923   84700 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "W0000 00:00:1767122700.077926   84700 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1767122700.156993   84700 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29789 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(max_length,)))\n",
    "model.add(layers.Embedding(30000, 256))\n",
    "model.add(layers.Conv1D(64, 2, activation='elu'))\n",
    "model.add(layers.Conv1D(32, 4, activation='elu'))\n",
    "model.add(layers.Conv1D(8, 8, activation='elu'))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(21*8, activation='relu')) # Before the latent space we are at (-1,21,8)\n",
    "model.add(layers.Conv1DTranspose(8, 8, activation='elu'))\n",
    "model.add(layers.Conv1DTranspose(32, 4, activation='elu'))\n",
    "model.add(layers.Conv1DTranspose(64, 2, activation='elu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45faa958-91db-4b15-9802-c6f4f9ddc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767122701.985544   84798 service.cc:158] XLA service 0x7fd7c404d140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767122701.985560   84798 service.cc:166]   StreamExecutor device (0): NVIDIA GeForce RTX 5090, Compute Capability 12.0a\n",
      "I0000 00:00:1767122702.024156   84798 dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1767122702.143087   84798 cuda_dnn.cc:463] Loaded cuDNN version 91002\n",
      "I0000 00:00:1767122704.369708   84798 device_compiler.h:208] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='mse', optimizer='adamax', metrics=['accuracy'])\n",
    "history = model.fit(x, x, epochs=50, batch_size=32, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d491baec-8d79-4ff1-ba82-d8206b7dfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "       'munnin sshd: failed logon attempt by margie.',\n",
    "       'hestia kernel: unknown operand from system process',\n",
    "       'munnin kernel: /dev/sda1 out of diskspace',\n",
    "       'munnin sudo: mike : TTY=pts/2 ; PWD=/home/mike ; USER=root ; COMMAND=/usr/sbin/adduser jim',\n",
    "       'munnin groupadd[1731]: group added to /etc/group: name=jim, GID=1001',\n",
    "       'munnin passwd[1742]: pam_unix(passwd:chauthtok): password changed for jim'\n",
    "       ]\n",
    "anomalies = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9891a133-5927-43f9-bca5-d3cb96d01900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses on known data:\n",
      "tf.Tensor([2547.3103    122.550415  103.366776  120.90019    98.71762   122.550415], shape=(6,), dtype=float32)\n",
      "Losses on anomalies:\n",
      "tf.Tensor([7956.436  3611.8918 4805.9834 4142.8804 6116.6274 2715.1367], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Losses on known data:')\n",
    "print(tf.keras.losses.mae(x[:6], model(x[:6])))\n",
    "print('Losses on anomalies:')\n",
    "print(tf.keras.losses.mae(anomalies, model(anomalies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c019b-0338-4642-a769-5bb66a2e2a1d",
   "metadata": {},
   "source": [
    "Notice the massive differences in losses. However, it would not make sense to try to decode the data back to log entries. They would all be nonsense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
